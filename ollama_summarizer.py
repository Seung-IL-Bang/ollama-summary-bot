import os
from langchain_community.llms import Ollama
from langchain.schema import BaseMessage
from langchain.text_splitter import RecursiveCharacterTextSplitter
from typing import List, Dict
import time

class OllamaSummarizer:
    """Ollamaë¥¼ ì‚¬ìš©í•œ ì™„ì „ ë¬´ë£Œ ê¸°ìˆ  ë¸”ë¡œê·¸ ìš”ì•½ í´ë˜ìŠ¤"""
    def __init__(self, model_name: str = "llama3.2"):
        print(f"ğŸ¦™ Ollama ëª¨ë¸ '{model_name}' ì´ˆê¸°í™” ì¤‘...")
        
        try:
            self.llm = Ollama(
                model=model_name,
                temperature=0.1
                # OllamaëŠ” ë¡œì»¬ ì‹¤í–‰ì´ë¯€ë¡œ íƒ€ì„ì•„ì›ƒì„ ê¸¸ê²Œ ì„¤ì •
                # request_timeout=60.0
            )
            
            # ëª¨ë¸ í…ŒìŠ¤íŠ¸
            test_response = self.llm("ì•ˆë…•í•˜ì„¸ìš”!")
            print(f"âœ… Ollama ëª¨ë¸ '{model_name}' ì¤€ë¹„ ì™„ë£Œ!")
            
        except Exception as e:
            print(f"âŒ Ollama ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            print("ğŸ’¡ í•´ê²° ë°©ë²•:")
            print("1. 'ollama serve' ëª…ë ¹ì–´ë¡œ Ollama ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸")
            print(f"2. 'ollama pull {model_name}' ëª…ë ¹ì–´ë¡œ ëª¨ë¸ì´ ì„¤ì¹˜ë˜ì—ˆëŠ”ì§€ í™•ì¸")
            raise e
        
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=2000,  # OllamaëŠ” ê¸´ í…ìŠ¤íŠ¸ ì²˜ë¦¬ê°€ ëŠë¦´ ìˆ˜ ìˆìŒ
            chunk_overlap=100,
            length_function=len
        )
    
    def summarize_single_article(self, article: Dict, summary_style: str = "technical") -> Dict:
        """ë‹¨ì¼ ê¸°ì‚¬ ìš”ì•½ (Ollama ë²„ì „)"""
        try:
            if "error" in article:
                return article
            
            # ìš”ì•½í•  í…ìŠ¤íŠ¸ ì¤€ë¹„ (ì§§ê²Œ ìœ ì§€)
            content = article.get('content', article.get('summary', ''))
            if len(content) > 2000:
                content = content[:2000] + "..."
            
            text_to_summarize = f"""
            ì œëª©: {article['title']}
            ì‘ì„±ì: {article['author']}
            
            ë‚´ìš©:
            {content}
            """
            
            # Ollamaì— ë§ëŠ” í”„ë¡¬í”„íŠ¸ (í•œêµ­ì–´/ì˜ì–´ í˜¼ìš©)
            prompts = {
                "technical": """
                ë‹¤ìŒ ê¸°ìˆ  ë¸”ë¡œê·¸ ê¸€ì„ ê¸°ìˆ ì  ê´€ì ì—ì„œ ìš”ì•½í•´ì£¼ì„¸ìš”:
                - ì‚¬ìš©ëœ ê¸°ìˆ /ë„êµ¬
                - í•´ê²°í•œ ë¬¸ì œ
                - í•µì‹¬ ì†”ë£¨ì…˜
                - ì¤‘ìš”í•œ ì¸ì‚¬ì´íŠ¸
                """,
                "business": """
                ë‹¤ìŒ ê¸°ìˆ  ë¸”ë¡œê·¸ ê¸€ì„ ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì ì—ì„œ ìš”ì•½í•´ì£¼ì„¸ìš”:
                - ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸
                - ì„±ëŠ¥ ê°œì„  ì‚¬í•­
                - ë¹„ìš© ì ˆê° íš¨ê³¼
                - ì‚¬ìš©ì ê²½í—˜ ê°œì„ 
                """,
                "brief": """
                ë‹¤ìŒ ê¸°ìˆ  ë¸”ë¡œê·¸ ê¸€ì„ 3-4ì¤„ë¡œ ê°„ë‹¨íˆ ìš”ì•½í•´ì£¼ì„¸ìš”:
                - í•µì‹¬ ë‚´ìš©ë§Œ ì¶”ì¶œ
                - ê¸°ìˆ ì  ìš©ì–´ëŠ” ê°„ë‹¨íˆ ì„¤ëª…
                """
            }
            
            prompt = prompts.get(summary_style, prompts["technical"])
            full_prompt = f"{prompt}\n\n{text_to_summarize}"
            
            print(f"ğŸ¤– '{article['title'][:30]}...' ìš”ì•½ ì¤‘...")
            
            # Ollama ì‹¤í–‰ (ì‹œê°„ì´ ì¢€ ê±¸ë¦´ ìˆ˜ ìˆìŒ)
            start_time = time.time()
            summary = self.llm(full_prompt)
            elapsed_time = time.time() - start_time
            
            print(f"âœ… ìš”ì•½ ì™„ë£Œ ({elapsed_time:.1f}ì´ˆ)")
            
            return {
                "title": article["title"],
                "link": article["link"],
                "author": article["author"],
                "published": article["published"] or article["updated"] or '',
                "summary": summary,
                "summary_style": summary_style,
                "processing_time": f"{elapsed_time:.1f}ì´ˆ"
            }
            
        except Exception as e:
            print(f"âŒ ìš”ì•½ ì‹¤íŒ¨: {str(e)}")
            return {
                "title": article.get("title", "ì•Œ ìˆ˜ ì—†ëŠ” ì œëª©"),
                "error": f"Ollama ìš”ì•½ ì‹¤íŒ¨: {str(e)}"
            }

    def summarize_multiple_articles(self, articles: List[Dict], summary_style: str = "technical") -> List[Dict]:
        """ì—¬ëŸ¬ ê¸°ì‚¬ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ìš”ì•½"""
        summaries = []
        
        print(f"ğŸ“š ì´ {len(articles)}ê°œ ê¸°ì‚¬ ìš”ì•½ ì‹œì‘...")
        
        for i, article in enumerate(articles, 1):
            print(f"\nğŸ”„ ì§„í–‰ìƒí™©: {i}/{len(articles)}")
            summary = self.summarize_single_article(article, summary_style)
            summaries.append(summary)
            
            # ë¡œì»¬ ëª¨ë¸ì´ë¯€ë¡œ ê³¼ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ì§§ì€ ëŒ€ê¸°
            if i < len(articles):
                time.sleep(1)
        
        print(f"\nğŸ‰ ëª¨ë“  ìš”ì•½ ì™„ë£Œ!")
        return summaries

    def create_digest(self, summaries: List[Dict], blog_name: str) -> str:
        """ì—¬ëŸ¬ ìš”ì•½ì„ í•˜ë‚˜ì˜ ë‹¤ì´ì œìŠ¤íŠ¸ë¡œ í†µí•©"""
        try:
            valid_summaries = [s for s in summaries if "error" not in s]
            
            if not valid_summaries:
                return "ìš”ì•½í•  ìˆ˜ ìˆëŠ” ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤."
            
            # ìš”ì•½ë“¤ì„ ê°„ë‹¨íˆ ê²°í•©
            articles_text = ""
            for i, summary in enumerate(valid_summaries[:3], 1):  # ìµœëŒ€ 3ê°œë§Œ ì‚¬ìš©
                articles_text += f"\n{i}. {summary['title']}\nìš”ì•½: {summary['summary']}\n"
            
            digest_prompt = f"""ì•„ë˜ëŠ” {blog_name}ì˜ ìµœì‹  ê¸°ìˆ  ë¸”ë¡œê·¸ ìš”ì•½ë“¤ì…ë‹ˆë‹¤.
                ì´ë“¤ì„ ì¢…í•©í•˜ì—¬ ë‹¤ìŒê³¼ ê°™ì€ ë‹¤ì´ì œìŠ¤íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:
                1. ì „ì²´ì ì¸ ê¸°ìˆ  íŠ¸ë Œë“œ (2-3ë¬¸ì¥)
                2. ì£¼ìš” í˜ì‹  ì‚¬í•­ë“¤ (2-3ë¬¸ì¥)  
                3. ê°œë°œìë“¤ì´ ì£¼ëª©í•  ì ë“¤ (2-3ë¬¸ì¥)

                ê°„ê²°í•˜ê³  ì‹¤ìš©ì ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.

                ê¸°ì‚¬ ìš”ì•½ë“¤:
                {articles_text}
                """
            
            print("ğŸ“° ì „ì²´ ë‹¤ì´ì œìŠ¤íŠ¸ ìƒì„± ì¤‘...")
            digest = self.llm(digest_prompt)
            print("âœ… ë‹¤ì´ì œìŠ¤íŠ¸ ìƒì„± ì™„ë£Œ!")
            
            return digest
            
        except Exception as e:
            return f"ë‹¤ì´ì œìŠ¤íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}"

    def get_available_models(self) -> List[str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ Ollama ëª¨ë¸ ëª©ë¡ ë°˜í™˜"""
        try:
            import subprocess
            result = subprocess.run(['ollama', 'list'], capture_output=True, text=True)
            if result.returncode == 0:
                lines = result.stdout.strip().split('\n')[1:]  # í—¤ë” ì œì™¸
                models = [line.split()[0] for line in lines if line.strip()]
                return models
            return []
        except:
            return ["empty"]  # ê¸°ë³¸ê°’